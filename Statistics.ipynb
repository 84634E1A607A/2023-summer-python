{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据分析\n",
    "\n",
    "## 词频分析\n",
    "\n",
    "首先我对所有新闻内容进行了分词, 并对词频进行了分析.\n",
    "\n",
    "分词的 python 脚本位于 `./KeywordAnalyser.py`.\n",
    "\n",
    "用 wordcloud 包建立了词云, 结果如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import sqlite3\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PureSymbolRe = re.compile('')\n",
    "\n",
    "tags = {}\n",
    "conn = sqlite3.connect('newsInfo.db')\n",
    "cursor = conn.execute(\"SELECT * FROM (SELECT word, SUM(count) AS cnt FROM words LEFT JOIN news ON news.docid = words.docid WHERE news.created_at >= 1693267200 GROUP BY word)t ORDER BY cnt DESC\")\n",
    "\n",
    "for row in cursor:\n",
    "    if len(row[0]) > 1:\n",
    "        tags[row[0]] = row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_path = 'C:/Windows/Fonts/msyh.ttc'\n",
    "wordcloud = WordCloud(font_path=font_path, width=1000, height=1000, max_words=100, background_color='white').generate_from_frequencies(tags)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 情感分析\n",
    "\n",
    "使用 cemotion 库进行了对部分主题文章的情感分析. 由于爬取的数据包含较多苹果区的文本, 我对以 iPhone 为标题进行了情感分析:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cemotion import Cemotion\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "ImagePlaceholderRe = re.compile(r'<_IMAGE_\\d+_.*?_/>')\n",
    "\n",
    "c = Cemotion()\n",
    "\n",
    "dbconn = sqlite3.connect('newsInfo.db')\n",
    "news = pd.DataFrame(\n",
    "    dbconn.execute('SELECT news.title, contents.content, news.created_at FROM news LEFT JOIN contents ON news.docid = contents.docid WHERE title LIKE \"%%iPhone%%\" ORDER BY created_at ASC').fetchall(),\n",
    "    columns=['title', 'content', 'created_at'],\n",
    ").dropna()\n",
    "news['created_at'] = pd.to_datetime(news['created_at'], unit='s')\n",
    "\n",
    "def ParseNewsContent(content: str) -> list[str]:\n",
    "    # Remove image placeholders\n",
    "    ImagePlaceholderRe.sub('', content)\n",
    "\n",
    "    # The first line is always ads or author or sth unimportant\n",
    "    content = content.splitlines()[1:]\n",
    "\n",
    "    # Strip all lines and remove lines too short\n",
    "    for i in range(len(content)):\n",
    "        content[i] = content[i].strip()\n",
    "    \n",
    "    content = list(filter(lambda x: len(x) > 5, content))\n",
    "    return content\n",
    "\n",
    "news['content'] = news['content'].apply(ParseNewsContent)\n",
    "\n",
    "def GetPrediction(data) -> float:\n",
    "    # title_emotion = c.predict(data['title'])\n",
    "    content_emotion = c.predict(' '.join(data['content']))\n",
    "    # print(f'Parsed {data[\"title\"]}: {title_emotion} {content_emotion}')\n",
    "    return content_emotion # title_emotion * 0.4 + content_emotion * 0.6\n",
    "\n",
    "\n",
    "news['emotion'] = news.apply(GetPrediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import datetime\n",
    "\n",
    "font = {'fontname': 'Microsoft YaHei'}\n",
    "\n",
    "timestamp = np.array(news['created_at'].apply(lambda x: x.timestamp())).reshape(-1, 1)\n",
    "model = LinearRegression().fit(X=timestamp, y=np.array(news['emotion']).reshape(-1, 1))\n",
    "\n",
    "image = plt.figure(figsize=(8, 6))\n",
    "plt.scatter(news['created_at'], news['emotion'], s=1)\n",
    "plt.plot(news['created_at'], model.predict(timestamp), color='r')\n",
    "plt.xlabel('时间', font)\n",
    "plt.ylabel('情感值', font)\n",
    "plt.title('iPhone 情感值散点图数据补齐版', font)\n",
    "plt.axhline(y=np.average(news['emotion']), color='g', linestyle='--')\n",
    "plt.axvline(x=datetime.datetime(2020, 10, 14, 0, 0, 0), color='#00800040', linestyle='-')\n",
    "plt.text(datetime.datetime(2020, 10, 14, 0, 0, 0), -0.03, 'iPhone 12', font)\n",
    "plt.axvline(x=datetime.datetime(2021, 9, 14, 0, 0, 0), color='#00800040', linestyle='-')\n",
    "plt.text(datetime.datetime(2021, 9, 14, 0, 0, 0), -0.03, 'iPhone 13', font)\n",
    "plt.axvline(x=datetime.datetime(2022, 9, 8, 0, 0, 0), color='#00800040', linestyle='-')\n",
    "plt.text(datetime.datetime(2022, 9, 8, 0, 0, 0), -0.03, 'iPhone 14', font)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关注程度\n",
    "\n",
    "我们对2023年以来新浪科技对包括 汽车 (燃油车, 电动车等), 电脑 (笔记本, 台式机组件等), 手机, 物联网设备, 人工智能 等类型的关注度 (涉及到的文章占所有文章占比) 进行了统计:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "StartTimestamp = 1672531200\n",
    "\n",
    "dbconn = sqlite3.connect('newsInfo.db')\n",
    "\n",
    "news = dbconn.execute(f'SELECT news.docid, news.title, news.created_at FROM news LEFT JOIN contents ON news.docid = contents.docid WHERE news.created_at >= {StartTimestamp} ORDER BY created_at ASC').fetchall()\n",
    "\n",
    "car_keyword = [\"汽车\", \"燃油车\", \"电动车\", \"电动汽车\", \"燃油\"]\n",
    "pc_keyword = [\"CPU\", \"笔记本\", \"电脑\", \"主机\", \"显卡\", \"GPU\"]\n",
    "game_keyword = [\"游戏\", \"游戏机\", \"游戏主机\"]\n",
    "mobile_keyword = [\"手机\", \"平板\"]\n",
    "web_keyword = [\"网站\", \"网页\", \"互联网\", \"TCP\", \"UDP\", \"运营商\", \"路由器\", \"交换机\"]\n",
    "iot_keyword = [\"物联网\", \"智能家居\", \"智能穿戴\", \"XR\", \"AR\", \"VR\", \"智能手表\", \"Watch\", \"扫地机器人\"]\n",
    "ai_keyword = [\"AI\", \"大模型\", \"人工智能\"]\n",
    "os_keyword = [\"操作系统\", \"Windows\", \"Linux\", \"MacOS\", \"iOS\", \"Android\", \"HarmonyOS\", \"OS\"]\n",
    "health_keyword = [\"医疗\", \"健康\", \"疫苗\", \"医学\"]\n",
    "\n",
    "def GetCat(cat: list[str]):\n",
    "    cat = ','.join(f'\"{x}\"' for x in cat)\n",
    "    # print(f'SELECT news.docid FROM words LEFT JOIN news ON news.docid = words.docid WHERE word IN ({cat}) AND news.created_at >= {StartTimestamp} GROUP BY news.docid')\n",
    "    return set(i[0] for i in dbconn.execute(f'SELECT news.docid FROM words LEFT JOIN news ON news.docid = words.docid WHERE word IN ({cat}) AND news.created_at >= {StartTimestamp} GROUP BY news.docid'))\n",
    "\n",
    "car_cat = GetCat(car_keyword)\n",
    "pc_cat = GetCat(pc_keyword)\n",
    "game_cat = GetCat(game_keyword)\n",
    "mobile_cat = GetCat(mobile_keyword)\n",
    "web_cat = GetCat(web_keyword)\n",
    "iot_cat = GetCat(iot_keyword)\n",
    "ai_cat = GetCat(ai_keyword)\n",
    "os_cat = GetCat(os_keyword)\n",
    "health_cat = GetCat(health_keyword)\n",
    "other_cat = set(n[0] for n in news) - car_cat - pc_cat - mobile_cat - game_cat - iot_cat - ai_cat - web_cat - health_cat - os_cat\n",
    "\n",
    "cat_names = ['汽车', '电脑', '游戏', '手机', '物联网', 'AI', '互联网', '操作系统', '健康', '其他']\n",
    "cat_data = np.array([len(car_cat), len(pc_cat), len(game_cat), len(mobile_cat), len(iot_cat), len(ai_cat), len(web_cat), len(os_cat), len(health_cat), len(other_cat)]) / len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(other_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'SimHei'\n",
    "graph = plt.figure(figsize=(8, 6))\n",
    "plt.bar_label(plt.bar(cat_names, cat_data), fmt='%.2f')\n",
    "plt.xlabel('分类', font)\n",
    "plt.ylabel('新闻数量', font)\n",
    "plt.title('新闻分类统计', font)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
